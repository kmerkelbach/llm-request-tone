{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66828417-33bb-44ce-9b83-342a5cda4ae9",
   "metadata": {},
   "source": [
    "# Prototype: LLM Tone Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c8c81-1a2c-4a20-b5c2-2c5d51bc6a71",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039d70c6-3b91-496d-ab9f-3bbfc107f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "# AI\n",
    "from datasets import Dataset, load_dataset\n",
    "from openai import OpenAI\n",
    "from lm_eval import simple_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3258e096-e9b7-47fd-98f9-42ea39f6c3ec",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92cae94f-c263-4120-ab1e-21d368474610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name\n",
    "model = \"accounts/fireworks/models/qwen3-30b-a3b-thinking-2507\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e23ce5-8616-4940-b89c-d1a15b6dbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API credentials\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "base_url = os.environ.get(\"OPENAI_API_BASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c50dbd-2f59-48c5-a8ce-411a60992a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up fireworks API\n",
    "fireworks_client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2713126-b1f0-4e29-958d-57eab743e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(message: str) -> str:\n",
    "    # Call API\n",
    "    response = fireworks_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message,\n",
    "            }\n",
    "        ],\n",
    "        model=model\n",
    "    )\n",
    "\n",
    "    # Extract response\n",
    "    resp = response.choices[0].message.content\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a374ff-0709-498a-a4d2-e980993a1bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user asked \"What's up? Tell me the result of 1+1.\" Let me break this down.\n",
      "\n",
      "First, \"What's up?\" is a casual greeting, so they're probably just being friendly or testing if I'm responsive. Then they want the sum of 1+1. That's really basic math, so they might be checking if I can handle simple calculations or just making small talk.\n",
      "\n",
      "Hmm, why would someone ask 1+1 in a chat? Maybe they're new to using AI and want to verify if the assistant works. Or perhaps they're just messing around to see the reaction. Either way, it's a straightforward request.\n",
      "\n",
      "I should keep it simple and friendly. No need for complex explanations since it's a math question. Just give the answer clearly and add a bit of warmth to match their casual tone. \n",
      "\n",
      "Wait—should I consider any possible tricks? Like, in some contexts 1+1 could mean something else (e.g., binary or wordplay), but they didn't hint at that. The safest bet is standard arithmetic. \n",
      "\n",
      "Also, they said \"result,\" so I'll just state \"2\" without overcomplicating. And since they started with \"What's up?\", I'll mirror that casual vibe in the reply. \n",
      "\n",
      "*Double-checking math*: 1 + 1 = 2. Yep, solid. No uncertainty here. \n",
      "\n",
      "Final plan: Respond with the answer + a cheerful \"Hey!\" to keep it light. No extra fluff—they didn't ask for a lesson, just the result.\n",
      "</think>\n",
      "\n",
      "Hey! 😄  \n",
      "The result of **1 + 1** is **2**.  \n",
      "\n",
      "Simple math, but always great to confirm! Let me know if you'd like to try something harder (or just want to chat). 😊\n"
     ]
    }
   ],
   "source": [
    "print(call_llm(\"What's up? Tell me the result of 1+1.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96c2ad-4454-4244-8180-3fad0924f4f1",
   "metadata": {},
   "source": [
    "## LM-Eval\n",
    "Using lm-eval (https://github.com/EleutherAI/lm-evaluation-harness) for evaluation. It supports many benchmarks and has prompting and post-processing code built-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4fb4bd1-d210-4515-aa28-4301c3fa041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pretrained=model=accounts/fireworks/models/qwen3-30b-a3b-thinking-2507,base_url=https://api.fireworks.ai/inference/v1/completions,api_key=fw_3ZRKwEjRhyHBNAPd5FDd4wrF,temperature=0,tokenizer=Qwen/Qwen2.5-7B-Instruct,tokenizer_backend=huggingface,trust_remote_code=True,max_retries=3,tokenized_requests=False,\n",
      "        appears to be an instruct or chat variant but chat template is not applied. Recommend setting `apply_chat_template` (optionally\n",
      "        `fewshot_as_multiturn`).\n",
      "Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_college_biology from None to 5\n",
      "Overwriting default num_fewshot of mmlu_computer_security from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_college_physics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5\n",
      "Overwriting default num_fewshot of mmlu_astronomy from None to 5\n",
      "Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_college_computer_science from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_physics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_anatomy from None to 5\n",
      "Overwriting default num_fewshot of mmlu_college_chemistry from None to 5\n",
      "Overwriting default num_fewshot of mmlu_college_mathematics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_machine_learning from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_biology from None to 5\n",
      "Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
      "Overwriting default num_fewshot of mmlu_college_medicine from None to 5\n",
      "Overwriting default num_fewshot of mmlu_medical_genetics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5\n",
      "Overwriting default num_fewshot of mmlu_miscellaneous from None to 5\n",
      "Overwriting default num_fewshot of mmlu_nutrition from None to 5\n",
      "Overwriting default num_fewshot of mmlu_virology from None to 5\n",
      "Overwriting default num_fewshot of mmlu_human_aging from None to 5\n",
      "Overwriting default num_fewshot of mmlu_professional_medicine from None to 5\n",
      "Overwriting default num_fewshot of mmlu_business_ethics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_management from None to 5\n",
      "Overwriting default num_fewshot of mmlu_professional_accounting from None to 5\n",
      "Overwriting default num_fewshot of mmlu_global_facts from None to 5\n",
      "Overwriting default num_fewshot of mmlu_marketing from None to 5\n",
      "Overwriting default num_fewshot of mmlu_econometrics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_human_sexuality from None to 5\n",
      "Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5\n",
      "Overwriting default num_fewshot of mmlu_sociology from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_professional_psychology from None to 5\n",
      "Overwriting default num_fewshot of mmlu_security_studies from None to 5\n",
      "Overwriting default num_fewshot of mmlu_public_relations from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_geography from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5\n",
      "Overwriting default num_fewshot of mmlu_world_religions from None to 5\n",
      "Overwriting default num_fewshot of mmlu_philosophy from None to 5\n",
      "Overwriting default num_fewshot of mmlu_jurisprudence from None to 5\n",
      "Overwriting default num_fewshot of mmlu_international_law from None to 5\n",
      "Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5\n",
      "Overwriting default num_fewshot of mmlu_professional_law from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5\n",
      "Overwriting default num_fewshot of mmlu_moral_disputes from None to 5\n",
      "Overwriting default num_fewshot of mmlu_prehistory from None to 5\n",
      "Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5\n",
      "Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5\n",
      "Overwriting default num_fewshot of mmlu_formal_logic from None to 5\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 46.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 111.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 102.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 108.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 116.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 99.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 111.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 121.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 119.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 79.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 95.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 74.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 80.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 111.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 114.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 115.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 118.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 111.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 102.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 117.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 107.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 100.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 103.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 110.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 114.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 112.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 106.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 114.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 115.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 107.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 106.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 121.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 117.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 111.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 108.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 93.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 93.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 88.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 90.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 75.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 108.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 119.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 120.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 117.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 112.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 111.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 116.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 114.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 121.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 118.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 119.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 122.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 120.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 115.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 119.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 114.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 113.20it/s]\n",
      "Requesting API:   0%|                                                                                                          | 0/228 [00:00<?, ?it/s]Context length (2687) + continuation length (1) > max_length (2047). Left truncating context.\n",
      "Requesting API:   0%|▍                                                                                                 | 1/228 [00:01<05:13,  1.38s/it]Context length (2687) + continuation length (1) > max_length (2047). Left truncating context.\n",
      "Requesting API:   1%|▊                                                                                                 | 2/228 [00:02<03:52,  1.03s/it]Context length (2687) + continuation length (1) > max_length (2047). Left truncating context.\n",
      "Requesting API:   1%|█▎                                                                                                | 3/228 [00:03<03:33,  1.05it/s]Context length (2687) + continuation length (1) > max_length (2047). Left truncating context.\n",
      "Requesting API:   2%|█▋                                                                                                | 4/228 [00:03<03:11,  1.17it/s]Context length (2164) + continuation length (1) > max_length (2047). Left truncating context.\n",
      "Requesting API:   2%|██▏                                                                                               | 5/228 [00:04<02:51,  1.30it/s]Context length (2164) + continuation length (1) > max_length (2047). Left truncating context.\n",
      "Requesting API:   3%|██▌                                                                                               | 6/228 [00:05<02:55,  1.27it/s]Context length (2164) + continuation length (1) > max_length (2047). Left truncating context.\n",
      "Requesting API:   3%|███                                                                                               | 7/228 [00:05<02:51,  1.29it/s]Context length (2164) + continuation length (1) > max_length (2047). Left truncating context.\n",
      "Requesting API: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 228/228 [02:33<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mmlu': {'acc,none': 0.9298245614035088,\n",
      "          'acc_stderr,none': 'N/A',\n",
      "          'alias': 'mmlu'},\n",
      " 'mmlu_abstract_algebra': {'acc,none': 1.0,\n",
      "                           'acc_stderr,none': 'N/A',\n",
      "                           'alias': '  - abstract_algebra'},\n",
      " 'mmlu_anatomy': {'acc,none': 1.0,\n",
      "                  'acc_stderr,none': 'N/A',\n",
      "                  'alias': '  - anatomy'},\n",
      " 'mmlu_astronomy': {'acc,none': 1.0,\n",
      "                    'acc_stderr,none': 'N/A',\n",
      "                    'alias': '  - astronomy'},\n",
      " 'mmlu_business_ethics': {'acc,none': 1.0,\n",
      "                          'acc_stderr,none': 'N/A',\n",
      "                          'alias': '  - business_ethics'},\n",
      " 'mmlu_clinical_knowledge': {'acc,none': 1.0,\n",
      "                             'acc_stderr,none': 'N/A',\n",
      "                             'alias': '  - clinical_knowledge'},\n",
      " 'mmlu_college_biology': {'acc,none': 1.0,\n",
      "                          'acc_stderr,none': 'N/A',\n",
      "                          'alias': '  - college_biology'},\n",
      " 'mmlu_college_chemistry': {'acc,none': 1.0,\n",
      "                            'acc_stderr,none': 'N/A',\n",
      "                            'alias': '  - college_chemistry'},\n",
      " 'mmlu_college_computer_science': {'acc,none': 1.0,\n",
      "                                   'acc_stderr,none': 'N/A',\n",
      "                                   'alias': '  - college_computer_science'},\n",
      " 'mmlu_college_mathematics': {'acc,none': 1.0,\n",
      "                              'acc_stderr,none': 'N/A',\n",
      "                              'alias': '  - college_mathematics'},\n",
      " 'mmlu_college_medicine': {'acc,none': 1.0,\n",
      "                           'acc_stderr,none': 'N/A',\n",
      "                           'alias': '  - college_medicine'},\n",
      " 'mmlu_college_physics': {'acc,none': 1.0,\n",
      "                          'acc_stderr,none': 'N/A',\n",
      "                          'alias': '  - college_physics'},\n",
      " 'mmlu_computer_security': {'acc,none': 1.0,\n",
      "                            'acc_stderr,none': 'N/A',\n",
      "                            'alias': '  - computer_security'},\n",
      " 'mmlu_conceptual_physics': {'acc,none': 1.0,\n",
      "                             'acc_stderr,none': 'N/A',\n",
      "                             'alias': '  - conceptual_physics'},\n",
      " 'mmlu_econometrics': {'acc,none': 1.0,\n",
      "                       'acc_stderr,none': 'N/A',\n",
      "                       'alias': '  - econometrics'},\n",
      " 'mmlu_electrical_engineering': {'acc,none': 1.0,\n",
      "                                 'acc_stderr,none': 'N/A',\n",
      "                                 'alias': '  - electrical_engineering'},\n",
      " 'mmlu_elementary_mathematics': {'acc,none': 1.0,\n",
      "                                 'acc_stderr,none': 'N/A',\n",
      "                                 'alias': '  - elementary_mathematics'},\n",
      " 'mmlu_formal_logic': {'acc,none': 1.0,\n",
      "                       'acc_stderr,none': 'N/A',\n",
      "                       'alias': '  - formal_logic'},\n",
      " 'mmlu_global_facts': {'acc,none': 1.0,\n",
      "                       'acc_stderr,none': 'N/A',\n",
      "                       'alias': '  - global_facts'},\n",
      " 'mmlu_high_school_biology': {'acc,none': 1.0,\n",
      "                              'acc_stderr,none': 'N/A',\n",
      "                              'alias': '  - high_school_biology'},\n",
      " 'mmlu_high_school_chemistry': {'acc,none': 1.0,\n",
      "                                'acc_stderr,none': 'N/A',\n",
      "                                'alias': '  - high_school_chemistry'},\n",
      " 'mmlu_high_school_computer_science': {'acc,none': 1.0,\n",
      "                                       'acc_stderr,none': 'N/A',\n",
      "                                       'alias': '  - '\n",
      "                                                'high_school_computer_science'},\n",
      " 'mmlu_high_school_european_history': {'acc,none': 1.0,\n",
      "                                       'acc_stderr,none': 'N/A',\n",
      "                                       'alias': '  - '\n",
      "                                                'high_school_european_history'},\n",
      " 'mmlu_high_school_geography': {'acc,none': 1.0,\n",
      "                                'acc_stderr,none': 'N/A',\n",
      "                                'alias': '  - high_school_geography'},\n",
      " 'mmlu_high_school_government_and_politics': {'acc,none': 1.0,\n",
      "                                              'acc_stderr,none': 'N/A',\n",
      "                                              'alias': '  - '\n",
      "                                                       'high_school_government_and_politics'},\n",
      " 'mmlu_high_school_macroeconomics': {'acc,none': 1.0,\n",
      "                                     'acc_stderr,none': 'N/A',\n",
      "                                     'alias': '  - high_school_macroeconomics'},\n",
      " 'mmlu_high_school_mathematics': {'acc,none': 1.0,\n",
      "                                  'acc_stderr,none': 'N/A',\n",
      "                                  'alias': '  - high_school_mathematics'},\n",
      " 'mmlu_high_school_microeconomics': {'acc,none': 1.0,\n",
      "                                     'acc_stderr,none': 'N/A',\n",
      "                                     'alias': '  - high_school_microeconomics'},\n",
      " 'mmlu_high_school_physics': {'acc,none': 1.0,\n",
      "                              'acc_stderr,none': 'N/A',\n",
      "                              'alias': '  - high_school_physics'},\n",
      " 'mmlu_high_school_psychology': {'acc,none': 1.0,\n",
      "                                 'acc_stderr,none': 'N/A',\n",
      "                                 'alias': '  - high_school_psychology'},\n",
      " 'mmlu_high_school_statistics': {'acc,none': 1.0,\n",
      "                                 'acc_stderr,none': 'N/A',\n",
      "                                 'alias': '  - high_school_statistics'},\n",
      " 'mmlu_high_school_us_history': {'acc,none': 1.0,\n",
      "                                 'acc_stderr,none': 'N/A',\n",
      "                                 'alias': '  - high_school_us_history'},\n",
      " 'mmlu_high_school_world_history': {'acc,none': 1.0,\n",
      "                                    'acc_stderr,none': 'N/A',\n",
      "                                    'alias': '  - high_school_world_history'},\n",
      " 'mmlu_human_aging': {'acc,none': 1.0,\n",
      "                      'acc_stderr,none': 'N/A',\n",
      "                      'alias': '  - human_aging'},\n",
      " 'mmlu_human_sexuality': {'acc,none': 1.0,\n",
      "                          'acc_stderr,none': 'N/A',\n",
      "                          'alias': '  - human_sexuality'},\n",
      " 'mmlu_humanities': {'acc,none': 0.8461538461538461,\n",
      "                     'acc_stderr,none': 'N/A',\n",
      "                     'alias': ' - humanities'},\n",
      " 'mmlu_international_law': {'acc,none': 1.0,\n",
      "                            'acc_stderr,none': 'N/A',\n",
      "                            'alias': '  - international_law'},\n",
      " 'mmlu_jurisprudence': {'acc,none': 0.0,\n",
      "                        'acc_stderr,none': 'N/A',\n",
      "                        'alias': '  - jurisprudence'},\n",
      " 'mmlu_logical_fallacies': {'acc,none': 1.0,\n",
      "                            'acc_stderr,none': 'N/A',\n",
      "                            'alias': '  - logical_fallacies'},\n",
      " 'mmlu_machine_learning': {'acc,none': 0.0,\n",
      "                           'acc_stderr,none': 'N/A',\n",
      "                           'alias': '  - machine_learning'},\n",
      " 'mmlu_management': {'acc,none': 1.0,\n",
      "                     'acc_stderr,none': 'N/A',\n",
      "                     'alias': '  - management'},\n",
      " 'mmlu_marketing': {'acc,none': 1.0,\n",
      "                    'acc_stderr,none': 'N/A',\n",
      "                    'alias': '  - marketing'},\n",
      " 'mmlu_medical_genetics': {'acc,none': 1.0,\n",
      "                           'acc_stderr,none': 'N/A',\n",
      "                           'alias': '  - medical_genetics'},\n",
      " 'mmlu_miscellaneous': {'acc,none': 1.0,\n",
      "                        'acc_stderr,none': 'N/A',\n",
      "                        'alias': '  - miscellaneous'},\n",
      " 'mmlu_moral_disputes': {'acc,none': 1.0,\n",
      "                         'acc_stderr,none': 'N/A',\n",
      "                         'alias': '  - moral_disputes'},\n",
      " 'mmlu_moral_scenarios': {'acc,none': 1.0,\n",
      "                          'acc_stderr,none': 'N/A',\n",
      "                          'alias': '  - moral_scenarios'},\n",
      " 'mmlu_nutrition': {'acc,none': 1.0,\n",
      "                    'acc_stderr,none': 'N/A',\n",
      "                    'alias': '  - nutrition'},\n",
      " 'mmlu_other': {'acc,none': 0.9230769230769231,\n",
      "                'acc_stderr,none': 'N/A',\n",
      "                'alias': ' - other'},\n",
      " 'mmlu_philosophy': {'acc,none': 1.0,\n",
      "                     'acc_stderr,none': 'N/A',\n",
      "                     'alias': '  - philosophy'},\n",
      " 'mmlu_prehistory': {'acc,none': 0.0,\n",
      "                     'acc_stderr,none': 'N/A',\n",
      "                     'alias': '  - prehistory'},\n",
      " 'mmlu_professional_accounting': {'acc,none': 1.0,\n",
      "                                  'acc_stderr,none': 'N/A',\n",
      "                                  'alias': '  - professional_accounting'},\n",
      " 'mmlu_professional_law': {'acc,none': 1.0,\n",
      "                           'acc_stderr,none': 'N/A',\n",
      "                           'alias': '  - professional_law'},\n",
      " 'mmlu_professional_medicine': {'acc,none': 1.0,\n",
      "                                'acc_stderr,none': 'N/A',\n",
      "                                'alias': '  - professional_medicine'},\n",
      " 'mmlu_professional_psychology': {'acc,none': 1.0,\n",
      "                                  'acc_stderr,none': 'N/A',\n",
      "                                  'alias': '  - professional_psychology'},\n",
      " 'mmlu_public_relations': {'acc,none': 1.0,\n",
      "                           'acc_stderr,none': 'N/A',\n",
      "                           'alias': '  - public_relations'},\n",
      " 'mmlu_security_studies': {'acc,none': 1.0,\n",
      "                           'acc_stderr,none': 'N/A',\n",
      "                           'alias': '  - security_studies'},\n",
      " 'mmlu_social_sciences': {'acc,none': 1.0,\n",
      "                          'acc_stderr,none': 'N/A',\n",
      "                          'alias': ' - social sciences'},\n",
      " 'mmlu_sociology': {'acc,none': 1.0,\n",
      "                    'acc_stderr,none': 'N/A',\n",
      "                    'alias': '  - sociology'},\n",
      " 'mmlu_stem': {'acc,none': 0.9473684210526315,\n",
      "               'acc_stderr,none': 'N/A',\n",
      "               'alias': ' - stem'},\n",
      " 'mmlu_us_foreign_policy': {'acc,none': 1.0,\n",
      "                            'acc_stderr,none': 'N/A',\n",
      "                            'alias': '  - us_foreign_policy'},\n",
      " 'mmlu_virology': {'acc,none': 0.0,\n",
      "                   'acc_stderr,none': 'N/A',\n",
      "                   'alias': '  - virology'},\n",
      " 'mmlu_world_religions': {'acc,none': 1.0,\n",
      "                          'acc_stderr,none': 'N/A',\n",
      "                          'alias': '  - world_religions'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from lm_eval import simple_evaluate\n",
    "import os\n",
    "\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "base_url = \"https://api.fireworks.ai/inference/v1/completions\"\n",
    "model = \"accounts/fireworks/models/qwen3-30b-a3b-thinking-2507\"\n",
    "\n",
    "results = simple_evaluate(\n",
    "    model=\"local-completions\",\n",
    "    model_args=(\n",
    "        f\"model={model},\"\n",
    "        f\"base_url={base_url},\"\n",
    "        f\"api_key={api_key},\"\n",
    "        \"temperature=0,\"\n",
    "        # tell lm-eval which *HF* tokenizer to load locally\n",
    "        \"tokenizer=Qwen/Qwen2.5-7B-Instruct,\"\n",
    "        \"tokenizer_backend=huggingface,\"\n",
    "        \"trust_remote_code=True,\"\n",
    "        # QoL for API backends\n",
    "        \"max_retries=3,tokenized_requests=False,\"\n",
    "    ),\n",
    "    tasks=[\"mmlu\"],\n",
    "    num_fewshot=5,\n",
    "    batch_size=1,\n",
    "    limit=1,\n",
    "    # IMPORTANT: do NOT apply a chat template for MMLU\n",
    "    # apply_chat_template=False  # (omit or set False)\n",
    ")\n",
    "\n",
    "pprint(results[\"results\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69065d5f-dd6d-45b8-9875-b937db9d0045",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031b31f-bfa8-46f9-beb2-8398f30fb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_pro = \"TIGER-Lab/MMLU-Pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ab44c-9db5-4f7b-9f04-a5f5072728d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_dataset(mmlu_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3bd43-eea2-40d6-8074-b0bf73c22faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"validation\"][60]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-tone",
   "language": "python",
   "name": "llm-tone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
